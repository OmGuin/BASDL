{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c17ddf",
   "metadata": {},
   "source": [
    "# Convolutional Variational Autoencoder Implementation on Burst Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f66c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyfilechooser import FileChooser\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from scipy.stats import linregress\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a031a7fc",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cac8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser('./')  # or use an absolute path if needed\n",
    "fc.title = \"<b>Select preprocessing parameter file</b>\"\n",
    "fc.filter_pattern = ['*.npz']  # Only show .par files\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f52d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(np.load(fc.selected, allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384cddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = np.array(data['handlesA'].item()['burst_windows'])\n",
    "labels = data['handlesA'].item()['species']\n",
    "assert windows.shape[0] == labels.shape[0]\n",
    "windows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = torch.tensor(windows, dtype=torch.float32)  # shape: (N, 21)\n",
    "min_val = X_raw.min()\n",
    "max_val = X_raw.max()\n",
    "\n",
    "X = (X_raw - min_val) / (max_val - min_val)\n",
    "X = X.unsqueeze(1)  # (N, 1, 21)\n",
    "#X = torch.log1p(X)\n",
    "if torch.cuda.is_available():\n",
    "    X = X.cuda()\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd152a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85cb504",
   "metadata": {},
   "source": [
    "## Convolutional VAE Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, input_length = 21, latent_dim = 3):\n",
    "        super(ConvVAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=3, padding=1), #(B, 16, 21)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2), #(B, 16, 10)\n",
    "            nn.Conv1d(16, 32, kernel_size=3, padding=1), #(B, 32, 10)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2), #(B, 32, 5)\n",
    "            #nn.Flatten() #(B, 160)\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(32*5, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(32*5, latent_dim)\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, 32*5)\n",
    "        self.decoder= nn.Sequential(\n",
    "            nn.Unflatten(1, (32, 5)), # (B, 32, 5)\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=4, stride=2), #(B, 16, 12)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(16, 1, kernel_size=4, stride=2), #(B, 1, 26)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(1, 1, kernel_size=6) # (B, 1, 21)\n",
    "        )\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        return mu + std * torch.randn_like(std)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        enc = self.encoder(x)\n",
    "        enc_flat = enc.view(x.size(0), -1)\n",
    "        mu = self.fc_mu(enc_flat)\n",
    "        logvar = self.fc_logvar(enc_flat)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        z_dec = self.decoder_input(z)\n",
    "        recon = self.decoder(z_dec)\n",
    "        return recon, mu, logvar\n",
    "    \n",
    "def vae_loss(recon, x, mu, logvar, beta=0.001):\n",
    "    recon_loss = F.mse_loss(recon, x, reduction='mean')\n",
    "    kl_div = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + beta*kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(TensorDataset(X), batch_size = 8)\n",
    "model = ConvVAE(input_length=21, latent_dim=3).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c9feb3",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        x_batch = batch[0].to(DEVICE)\n",
    "        recon, mu, logvar = model(x_batch)\n",
    "        loss = vae_loss(recon, x_batch, mu, logvar)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - Loss: {total_loss / len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35701c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "latents = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        x_batch = batch[0].to(DEVICE)\n",
    "        enc = model.encoder(x_batch)\n",
    "        enc_flat = enc.view(x_batch.size(0), -1)\n",
    "        mu = model.fc_mu(enc_flat)\n",
    "        latents.append(mu.cpu().numpy())\n",
    "        \n",
    "\n",
    "latents = np.concatenate(latents, axis=0)\n",
    "\n",
    "assert latents.shape[0] == len(labels)\n",
    "\n",
    "#pca = PCA(n_components=3)\n",
    "#z_pca = pca.fit_transform(latents)\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=latents[:, 0],\n",
    "    y=latents[:, 1],\n",
    "    z=latents[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=labels,\n",
    "        colorscale='viridis',\n",
    "        opacity=0.8,\n",
    "        colorbar=dict(title='Species')\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='PC1',\n",
    "        yaxis_title='PC2',\n",
    "        zaxis_title='PC3'\n",
    "    ),\n",
    "    title='Latent Space',\n",
    "    margin=dict(l=0, r=0, b=0, t=30)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=latents[:, 0][labels!=0],\n",
    "    y=latents[:, 1][labels!=0],\n",
    "    z=latents[:, 2][labels!=0],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=labels[labels!=0],\n",
    "        colorscale='viridis',\n",
    "        opacity=0.8,\n",
    "        colorbar=dict(title='Species')\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='PC1',\n",
    "        yaxis_title='PC2',\n",
    "        zaxis_title='PC3'\n",
    "    ),\n",
    "    title='Latent Space',\n",
    "    margin=dict(l=0, r=0, b=0, t=30)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=latents[:, 0][labels!=1],\n",
    "    y=latents[:, 1][labels!=1],\n",
    "    z=latents[:, 2][labels!=1],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=labels[labels!=1],\n",
    "        colorscale='viridis',\n",
    "        opacity=0.8,\n",
    "        colorbar=dict(title='Species')\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='PC1',\n",
    "        yaxis_title='PC2',\n",
    "        zaxis_title='PC3'\n",
    "    ),\n",
    "    title='Latent Space',\n",
    "    margin=dict(l=0, r=0, b=0, t=30)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 3\n",
    "num_samples = windows.shape[0]\n",
    "z = torch.randn(num_samples, latent_dim).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    decoded = model.decoder(model.decoder_input(z)) #[num_samples, 1, 21]\n",
    "    decoded = decoded.squeeze(1) #[num_samples, 21]\n",
    "generated_unscaled = decoded * (max_val - min_val) + min_val\n",
    "amplitudes = generated_unscaled.max(dim=1).values.cpu().numpy()\n",
    "\n",
    "#generated_amplitudes = np.max(decoded, axis = 1)\n",
    "#print(generated_amplitudes)\n",
    "bins = np.logspace(np.log10(max(min(amplitudes), 1e-6)), np.log10(max(amplitudes)), 20)\n",
    "hist, bin_edges = np.histogram(amplitudes, bins=bins)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "nonzero = hist > 0 & (bin_centers > 0)\n",
    "x = bin_centers[nonzero]\n",
    "y = hist[nonzero]\n",
    "\n",
    "log_x = np.log10(x)\n",
    "log_y = np.log10(y)\n",
    "slope, intercept, r_value, p_value, std_err = linregress(log_x, log_y)\n",
    "fit_y = 10**(slope * log_x + intercept)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.loglog(x, y, '-ro', label='Amplitude')\n",
    "plt.loglog(x, fit_y, '-bx', label=f'Power law: {slope:.2f}')\n",
    "plt.xlabel('Amplitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Burst Amplitudes')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig(os.path.join(f'{data['newdir'].item()}', \"ampdist\"))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e2591",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z_sample = torch.randn(1000, latent_dim).to(DEVICE)\n",
    "    recon = model.decoder(model.decoder_input(z_sample)).squeeze(1).cpu().numpy()\n",
    "    print(np.std(recon, axis=1))  # should not be all zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92997ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "latents = []\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        x_batch = batch[0].to(DEVICE)\n",
    "        enc = model.encoder(x_batch)\n",
    "        enc_flat = enc.view(x_batch.size(0), -1)\n",
    "        mu = model.fc_mu(enc_flat)\n",
    "        latents.append(mu.cpu().numpy())\n",
    "\n",
    "latents = np.vstack(latents)\n",
    "print(\"Latent mean:\", np.mean(latents, axis=0))\n",
    "print(\"Latent std:\", np.std(latents, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb3091",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.mean(mu, dim=0))\n",
    "print(torch.std(mu, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7feea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(mu.cpu().detach().numpy(), cmap=\"viridis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d72e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
